{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "Our project aims to use data collected by a Taiwanese National University's Civil Engineering Department to create a predictive model to see if a debtor will default on their credit or not. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "Improvements from peer review here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Angel Olivas\n",
    "- Hyunseo Park (missing)\n",
    "- Yuanzhen Zhu\n",
    "- Eric Dong"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This paper is aimed at researching and understanding the possibility of looking at how one can use machine learning models to analyze and predict whether or not a credit card will default. Defaulting is an issue that occurs when someone repeatedly doesn't pay their credit card bill, the bank closes the account, and there is a mark on their credit history. The goal is to figure out when a credit card bill would default; thus, we found a dataset on Kaggle that measures different statistics from various clients and looks at whether or not their account defaulted. This was measured in Taiwan, looking at various factors such as the credit accumulated, the history of past payments, billing amounts, and more. Through six different data mining methods, the study looks at around 30k clients. We will be using the data and manipulating it in a way that allows us to build a machine learning model off of it that allows us to predict debt default in a binary way."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Economic models often rely on broad trends that are quantified into aggregate satistics into how resources are distributed and flow in a society. However there are times where fundamental relationships between variables tend to be skewed one way or the other based on external factors leading to some confusion and investigation, these \"stylized facts\" that are essentially just understood relationships that inform us as to what is happening in a system. An example of this would be the relationship between interest rates and investments, which would be that as interest rates goes down, generally speaking investments go up. <a name=\"ouliaris\"></a>[<sup>[1]</sup>](#Ouliarisnote) One of the most famous example of this being prior to the 2008 financial crisis in United States, as interest rates decreased more people got into real estate that didn't have the capital to be doing so. This eventually lead to a bust because irresponsible lending to these creditors became rampant. But it also isn't unheard of for investments to decrease as interest rates go down, for example in Japan in the 1990's there was a period of uncertainty in the economy that created economic behaviour that needed to be stopped.<a name=\"neilsen\"></a>[<sup>[2]</sup>](#Neilsennote) When this is the case, it is important to look at smaller scale models to figure diagonse what is causing odd behaviour, and though it would be ideal to make classifier models that properly reflect the real world, often times predictive models are needed to gain insight to build classifier models. We aim to help create one of these smaller scale models for Taiwan as it's within our ability with the dataset we have, using data found in debt collection and payment history and monthly income level. The choice of our features is partially informed by both historical and newer models for consumer default risk, <a name=\"costaesilvanote\"></a>[<sup>[3]</sup>](#CostaeSilva) and aims to create a smaller model for analysis for tracking debt in Taiwan. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "The problem that we are aiming to solve is whether or not a certain client's credit card would default given different variables and factors. Some very useful information that we could use to create a model to predict a client's possibility to default - which is very clearly just a Yes or No. Some potential solutions that we were looking at given that the result is a binary classification of either positive or negative are either looking at Logistic Regression models or maybe even a Suport Vector Machine. Given our dataset, we have around 30 thousand clients to work with and approximately 23 explanatory variables that are chunked into around eight parts. However, the result of the problem should be entirely binary, a positive or negative stat as to whether or not the credit card account would default. All the explantory variables are measurable as the data is essentially just data about the clients and their credit history. In addition, the entire problem would be replicable as we can continue looking at different datasets and training our model based off of those, predicting whether or not certain credit card accounts would default."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "- Link to our dataset https://www.kaggle.com/datasets/utkarshx27/default-of-credit-card-clients-dataset \n",
    "\n",
    "- Dataset name: 'Predict Credit Card Defaulters' \n",
    "\n",
    "- The original dataset contains 25 columns/variables, and 30001 total observations, we will make selections from the original dataset in our project \n",
    "\n",
    "- An observation consists of 24 columns of X variables that in different degrees might relates to whether someone will default, and one y variable default payment (Yes = 1, No = 0) which is the classification of the observation \n",
    "\n",
    "- Some critical variables potentially include Amount of credit given, Education, Marital status, Age, History of past payment. Amount of credit given and Age are represented in continuous natural numbers, Education and Marital status are represented categorically by natural numbers, History of past payment is represented monthly across multiple columns with each column denoting number of months that the payment has been late with discrete numbers (-1 ~ 9) \n",
    "\n",
    "- We need to first select variables from the original datasets that we think are significant to the classfication. To create the feature matrix, we might need to one-hot encode the categorical variables, normalize continuous values. The datasets looks very clean form this stage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Our solution aims to make features of data found in the columns for credit given, repayment status, amount of bills, education, and amount paid per month. However, this gives us some wiggle room as the data collected for history of payment and amount of bill varialbes break down even further, therefore we aim to make a few different models that leverage expected relationships. We then plan to use ordinary least squares to create a binary prediction model, since the data is fairly clean, we do not believe there should be much of an issue in regard to data wrangling. Another method we have observed and may explore implementing is using logistic regression to instead show the probability of a creditor defaulting. As we analyze evaluation metrics, we hope to find the model that best delivers results.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One evaluation metrics we could use is AUC-ROC, which is 'Area under the ROC Curve'. This is a widely recognized evaluation metrics for classification model. This is derived by graphing the model's 'True positive rate'(True positive/(True Positive + False Negative)) versus 'False positive rate'(1 - (True Negative/(True Negative + False Positive))) which is always in conflicting tradeoffs in most models. A better model is characterized by having a bigger area under the ROC curve which says the model would have a larger TP rate and a smaller FP rate in its optimum point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recognize that our project may have real data privacy and ethics issues depending on what variables we decide to put into creating our model. Some variables such as Gender, Marriage status and Age may be very sensitive and private information, we will make sure that datas we use are completely anonymous and will not specify or harm any real entities that the data may subject to. Additionally, we will make sure that our model will be for research purposes only and will not be used to discriminate against any group or any person. Lastly, we can utilize tools such as 'deon' to check for data ethics issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our team will converse with eachother on our group chat\n",
    "* Our team will split work accordingly to fairness and ability\n",
    "* Our team will schedule meetings within a week in order to accomdoate changing schedules\n",
    "* Individidual members of the team are expected to follow the Project Timeline Proposal as best as possible\n",
    "* If issues arise with a submission for previously split work, individuals are expected to ask for help from other teammates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timeline for our project will follow a rough outline with the expectation that we have a submittable version of our project at least 3 days prior to each due date to finalize submissions and comb for errors.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 5/17  |  7 PM |  Individually assigned sections of proposal (all)  | Finalize Project Proposal Submission | \n",
    "| 5/21  |  5 PM |  Review methods for implementation of feature analysis (all)| Figure out which combinations of features produce better models with error metrics discussed prior by assigning models to each person for analysis | \n",
    "| 5/23  | 5 PM  |  Make sure project looks presentable for Peer Review (all) | Clean up project if there's anything that looks rough, discuss EDA individual assigments  |\n",
    "| 5/27  | 5 PM  | EDA assigned responsibilities (all) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 5/30  | 5 PM | Finalize wrangling/EDA; Begin programming for project (all) | Discuss/edit project code; Assure all models followed what we said they did |\n",
    "| 6/04  | 5 PM | Each model's analysis (all)| Discuss/edit full project |\n",
    "| 6/07  | 5 PM | NA | Discuss any responsiblities that may need to be taken care of |\n",
    "| 6/14  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"Ouliarisnote\"></a>1.[^](#Ouliaris): Ouliaris, S. (9 Dec 2021) What are Economic Models?. *International Monetary Fund*. https://www.imf.org/external/pubs/ft/fandd/2011/06/basics.html <br>\n",
    "<a name=\"Neilsennote\"></a>2.[^](#Neilsen,): Neilsen, B. (14 Jan 2022) The Lost Decade: Lessons from Japan's Real Estate Crisis. *Investopedia*. https://www.investopedia.com/articles/economics/08/japan-1990s-credit-crunch-liquidity-trap.asp <br>\n",
    "<a name=\"CostaeSilvanote\"></a>3.[^](#CostaeSilva,): Costa e Silva, E. (5 May 2020) TA logistic regression model for consumer default risk. *National Library of Medicine*. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9041570/ <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
